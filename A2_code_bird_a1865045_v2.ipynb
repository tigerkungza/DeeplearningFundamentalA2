{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a1e5f2",
   "metadata": {},
   "source": [
    "Import the packages and set the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8bae27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_2520\\56100754.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import os\n",
    "# Define data paths\n",
    "train_dir = 'train'\n",
    "val_dir = 'valid'\n",
    "test_dir = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c210bee",
   "metadata": {},
   "source": [
    "Set training, validilating and testing data. Each image has 112 x 112 resolution.  \n",
    "The dataset can be found at: https://www.kaggle.com/datasets/gpiosenka/100-bird-species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd079da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84635 images belonging to 525 classes.\n",
      "Found 2625 images belonging to 525 classes.\n",
      "Found 2625 images belonging to 525 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the ImageDataGenerator for training and validation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "# Define the training, validation, and test generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(112, 112),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    val_dir,  # Corrected to val_dir\n",
    "    target_size=(112, 112),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(  # Added test generator\n",
    "    test_dir,\n",
    "    target_size=(112, 112),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8782904",
   "metadata": {},
   "source": [
    "Define CNNs by the implemention of VGG16, ResNet50 and MobileNetV2.\n",
    "Reduce learning is set.\n",
    "Each architecture has the following parameters:\n",
    "+ the pre-trained base, a flattening layer, a dense layer with 512 units\n",
    "+ batch normalization, ReLU activation, a dropout layer for regularization\n",
    "+ the final classification layer with 525 units (representing the bird species) \n",
    "+ softmax activation for probability distribution. \n",
    "+ Adam optimizer\n",
    "+ a learning rate of  10^{-3}\n",
    "+ categorical cross-entropy loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf17bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-3)\n",
    "\n",
    "# Stop training when a monitored quantity has stopped improving.\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "def build_vgg_model():\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', input_shape=(112, 112, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, kernel_regularizer=l2(1e-4)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(525),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_resnet_model():\n",
    "    base_model = tf.keras.applications.ResNet50(weights='imagenet', input_shape=(112, 112, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, kernel_regularizer=l2(1e-4)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(525),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_mobilenet_model():\n",
    "    base_model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(112, 112, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, kernel_regularizer=l2(1e-4)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(525),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab06ae",
   "metadata": {},
   "source": [
    "Train each model with epoch 10. \n",
    "+ early stop is set to reduc computional burden\n",
    "+ Tensorboard is set to monitor loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11203125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 4.9597 - accuracy: 0.1307\n",
      "Epoch 1: val_loss improved from inf to 3.32571, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2584s 976ms/step - loss: 4.9597 - accuracy: 0.1307 - val_loss: 3.3257 - val_accuracy: 0.3806 - lr: 0.0010\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2645/2645 [==============================] - ETA: 0s - loss: 4.3793 - accuracy: 0.2099\n",
      "Epoch 2: val_loss improved from 3.32571 to 2.98703, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2311s 874ms/step - loss: 4.3793 - accuracy: 0.2099 - val_loss: 2.9870 - val_accuracy: 0.4389 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 4.1969 - accuracy: 0.2330\n",
      "Epoch 3: val_loss improved from 2.98703 to 2.79049, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2365s 894ms/step - loss: 4.1969 - accuracy: 0.2330 - val_loss: 2.7905 - val_accuracy: 0.4636 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 4.0754 - accuracy: 0.2489\n",
      "Epoch 4: val_loss improved from 2.79049 to 2.68553, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2584s 977ms/step - loss: 4.0754 - accuracy: 0.2489 - val_loss: 2.6855 - val_accuracy: 0.4796 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 4.0130 - accuracy: 0.2582\n",
      "Epoch 5: val_loss did not improve from 2.68553\n",
      "2645/2645 [==============================] - 2306s 872ms/step - loss: 4.0130 - accuracy: 0.2582 - val_loss: 2.6896 - val_accuracy: 0.4869 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.9519 - accuracy: 0.2698\n",
      "Epoch 6: val_loss improved from 2.68553 to 2.58338, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2555s 966ms/step - loss: 3.9519 - accuracy: 0.2698 - val_loss: 2.5834 - val_accuracy: 0.5143 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.9075 - accuracy: 0.2748\n",
      "Epoch 7: val_loss improved from 2.58338 to 2.56924, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2321s 878ms/step - loss: 3.9075 - accuracy: 0.2748 - val_loss: 2.5692 - val_accuracy: 0.5196 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.8700 - accuracy: 0.2817\n",
      "Epoch 8: val_loss improved from 2.56924 to 2.54874, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2303s 871ms/step - loss: 3.8700 - accuracy: 0.2817 - val_loss: 2.5487 - val_accuracy: 0.5204 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.8436 - accuracy: 0.2859\n",
      "Epoch 9: val_loss improved from 2.54874 to 2.50257, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2301s 870ms/step - loss: 3.8436 - accuracy: 0.2859 - val_loss: 2.5026 - val_accuracy: 0.5295 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.8154 - accuracy: 0.2910\n",
      "Epoch 10: val_loss improved from 2.50257 to 2.49352, saving model to best_model_vgg_n.h5\n",
      "2645/2645 [==============================] - 2307s 872ms/step - loss: 3.8154 - accuracy: 0.2910 - val_loss: 2.4935 - val_accuracy: 0.5288 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train VGG model\n",
    "vgg_model = build_vgg_model()\n",
    "vgg_checkpoint = ModelCheckpoint(filepath='best_model_vgg_n.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "vgg_tensorboard = TensorBoard(log_dir=os.path.join(os.getcwd(), 'logs/vgg_n'))\n",
    "vgg_history = vgg_model.fit(train_generator, validation_data=valid_generator, epochs=10, callbacks=[early_stopping, vgg_checkpoint, vgg_tensorboard, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4443b9de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 6.0603 - accuracy: 0.0148\n",
      "Epoch 1: val_loss improved from inf to 6.44562, saving model to best_model_resnet_n.h5\n",
      "2645/2645 [==============================] - 1997s 753ms/step - loss: 6.0603 - accuracy: 0.0148 - val_loss: 6.4456 - val_accuracy: 0.0156 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.8158 - accuracy: 0.0265\n",
      "Epoch 2: val_loss improved from 6.44562 to 5.91726, saving model to best_model_resnet_n.h5\n",
      "2645/2645 [==============================] - 1660s 627ms/step - loss: 5.8158 - accuracy: 0.0265 - val_loss: 5.9173 - val_accuracy: 0.0309 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.7262 - accuracy: 0.0303\n",
      "Epoch 3: val_loss did not improve from 5.91726\n",
      "2645/2645 [==============================] - 1588s 600ms/step - loss: 5.7262 - accuracy: 0.0303 - val_loss: 6.5004 - val_accuracy: 0.0145 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.6584 - accuracy: 0.0353\n",
      "Epoch 4: val_loss improved from 5.91726 to 5.71571, saving model to best_model_resnet_n.h5\n",
      "2645/2645 [==============================] - 1593s 602ms/step - loss: 5.6584 - accuracy: 0.0353 - val_loss: 5.7157 - val_accuracy: 0.0438 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.6142 - accuracy: 0.0379\n",
      "Epoch 5: val_loss improved from 5.71571 to 5.60896, saving model to best_model_resnet_n.h5\n",
      "2645/2645 [==============================] - 1583s 599ms/step - loss: 5.6142 - accuracy: 0.0379 - val_loss: 5.6090 - val_accuracy: 0.0461 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.5800 - accuracy: 0.0395\n",
      "Epoch 6: val_loss improved from 5.60896 to 5.54454, saving model to best_model_resnet_n.h5\n",
      "2645/2645 [==============================] - 1589s 601ms/step - loss: 5.5800 - accuracy: 0.0395 - val_loss: 5.5445 - val_accuracy: 0.0476 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.5404 - accuracy: 0.0418\n",
      "Epoch 7: val_loss did not improve from 5.54454\n",
      "2645/2645 [==============================] - 1592s 602ms/step - loss: 5.5404 - accuracy: 0.0418 - val_loss: 5.6627 - val_accuracy: 0.0537 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.5245 - accuracy: 0.0426\n",
      "Epoch 8: val_loss did not improve from 5.54454\n",
      "2645/2645 [==============================] - 1597s 604ms/step - loss: 5.5245 - accuracy: 0.0426 - val_loss: 6.2723 - val_accuracy: 0.0370 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.5062 - accuracy: 0.0443\n",
      "Epoch 9: val_loss did not improve from 5.54454\n",
      "2645/2645 [==============================] - 1603s 606ms/step - loss: 5.5062 - accuracy: 0.0443 - val_loss: 5.5854 - val_accuracy: 0.0427 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 5.4819 - accuracy: 0.0446\n",
      "Epoch 10: val_loss did not improve from 5.54454\n",
      "2645/2645 [==============================] - 1609s 608ms/step - loss: 5.4819 - accuracy: 0.0446 - val_loss: 5.9646 - val_accuracy: 0.0362 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train ResNet model\n",
    "resnet_model = build_resnet_model()\n",
    "resnet_checkpoint = ModelCheckpoint(filepath='best_model_resnet_n.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "resnet_tensorboard = TensorBoard(log_dir=os.path.join(os.getcwd(), 'logs/resnet_n'))\n",
    "resnet_history = resnet_model.fit(train_generator, validation_data=valid_generator, epochs=10, callbacks=[early_stopping, resnet_checkpoint, resnet_tensorboard, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18aa0d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 4.2990 - accuracy: 0.2730\n",
      "Epoch 1: val_loss improved from inf to 2.55653, saving model to best_model_mobilenet_n.h5\n",
      "2645/2645 [==============================] - 716s 269ms/step - loss: 4.2990 - accuracy: 0.2730 - val_loss: 2.5565 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.8521 - accuracy: 0.3551\n",
      "Epoch 2: val_loss improved from 2.55653 to 2.39618, saving model to best_model_mobilenet_n.h5\n",
      "2645/2645 [==============================] - 696s 263ms/step - loss: 3.8521 - accuracy: 0.3551 - val_loss: 2.3962 - val_accuracy: 0.6053 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.7255 - accuracy: 0.3752\n",
      "Epoch 3: val_loss improved from 2.39618 to 2.37381, saving model to best_model_mobilenet_n.h5\n",
      "2645/2645 [==============================] - 702s 265ms/step - loss: 3.7255 - accuracy: 0.3752 - val_loss: 2.3738 - val_accuracy: 0.6168 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.6365 - accuracy: 0.3886\n",
      "Epoch 4: val_loss improved from 2.37381 to 2.31300, saving model to best_model_mobilenet_n.h5\n",
      "2645/2645 [==============================] - 700s 265ms/step - loss: 3.6365 - accuracy: 0.3886 - val_loss: 2.3130 - val_accuracy: 0.6343 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.5767 - accuracy: 0.4002\n",
      "Epoch 5: val_loss improved from 2.31300 to 2.28259, saving model to best_model_mobilenet_n.h5\n",
      "2645/2645 [==============================] - 699s 264ms/step - loss: 3.5767 - accuracy: 0.4002 - val_loss: 2.2826 - val_accuracy: 0.6476 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.5333 - accuracy: 0.4043\n",
      "Epoch 6: val_loss did not improve from 2.28259\n",
      "2645/2645 [==============================] - 701s 265ms/step - loss: 3.5333 - accuracy: 0.4043 - val_loss: 2.3258 - val_accuracy: 0.6362 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.4919 - accuracy: 0.4113\n",
      "Epoch 7: val_loss improved from 2.28259 to 2.24897, saving model to best_model_mobilenet_n.h5\n",
      "2645/2645 [==============================] - 711s 269ms/step - loss: 3.4919 - accuracy: 0.4113 - val_loss: 2.2490 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.4557 - accuracy: 0.4186\n",
      "Epoch 8: val_loss did not improve from 2.24897\n",
      "2645/2645 [==============================] - 755s 286ms/step - loss: 3.4557 - accuracy: 0.4186 - val_loss: 2.2551 - val_accuracy: 0.6663 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.4364 - accuracy: 0.4215\n",
      "Epoch 9: val_loss did not improve from 2.24897\n",
      "2645/2645 [==============================] - 727s 275ms/step - loss: 3.4364 - accuracy: 0.4215 - val_loss: 2.2654 - val_accuracy: 0.6602 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "2645/2645 [==============================] - ETA: 0s - loss: 3.4148 - accuracy: 0.4264\n",
      "Epoch 10: val_loss did not improve from 2.24897\n",
      "2645/2645 [==============================] - 701s 265ms/step - loss: 3.4148 - accuracy: 0.4264 - val_loss: 2.3022 - val_accuracy: 0.6430 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train MobileNet model\n",
    "mobilenet_model = build_mobilenet_model()\n",
    "mobilenet_checkpoint = ModelCheckpoint(filepath='best_model_mobilenet_n.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "mobilenet_tensorboard = TensorBoard(log_dir=os.path.join(os.getcwd(), 'logs/mobilenet_n'))\n",
    "mobilenet_history = mobilenet_model.fit(train_generator, validation_data=valid_generator, epochs=10, callbacks=[early_stopping, mobilenet_checkpoint, mobilenet_tensorboard, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382ccb5",
   "metadata": {},
   "source": [
    "Open Tensorboard to monitor loss and accuracy during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27d73c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9300), started 16:30:38 ago. (Use '!kill 9300' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ad6be60b7f4f34c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ad6be60b7f4f34c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aeb59d",
   "metadata": {},
   "source": [
    "The trained models for each architectures are loaded and utilised to predict bird species of the test data to obtain the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0214fc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vgg': 0.5580952167510986,\n",
       " 'resnet': 0.0476190485060215,\n",
       " 'mobilenet': 0.6666666865348816}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# Define the architecture names\n",
    "architectures = ['vgg', 'resnet', 'mobilenet']\n",
    "\n",
    "# Load the best models for each architecture\n",
    "models = {}\n",
    "for arch in architectures:\n",
    "    model_path = f'best_model_{arch}_n.h5'\n",
    "    if os.path.exists(model_path):  # Check if the model file exists\n",
    "        models[arch] = load_model(model_path)\n",
    "    else:\n",
    "        print(f\"Model file for {arch} not found!\")\n",
    "\n",
    "# Evaluate each model on the test set\n",
    "accuracies = {}\n",
    "for arch, model in models.items():\n",
    "    loss, acc = model.evaluate(test_generator, verbose=0)\n",
    "    accuracies[arch] = acc\n",
    "\n",
    "accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
